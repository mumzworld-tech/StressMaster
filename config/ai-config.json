{
  "provider": "ollama",
  "model": "llama3.2:1b",
  "endpoint": "http://localhost:11434",
  "maxRetries": 3,
  "timeout": 30000,
  "options": {
    "temperature": 0.1,
    "num_predict": 256,
    "top_k": 5,
    "top_p": 0.8,
    "repeat_penalty": 1.1
  }
}
